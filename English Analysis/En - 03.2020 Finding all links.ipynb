{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/i/web/status/1242964476669898754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://conservativechoicecampaign.com/fast-and-furious-the-deep-state-playbook-revealed/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/i/web/status/1242964474723794944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/i/web/status/1242964475445051398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.politicshome.com/news/article/italian-officials-demand-health-minister-nadine-dorries-delete-fake-news-about-coronavirus-patients#.Xnvwe3DEjaI.twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775410</th>\n",
       "      <td>https://twitter.com/i/web/status/1245138810297606149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775411</th>\n",
       "      <td>https://twitter.com/i/web/status/1245138809290973187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775412</th>\n",
       "      <td>https://twitter.com/i/web/status/1245138810863665152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775413</th>\n",
       "      <td>https://twitter.com/i/web/status/1245138811362906112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775414</th>\n",
       "      <td>https://twitter.com/i/web/status/1245138809555206144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>775415 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                      urls\n",
       "0                                                                                                                     https://twitter.com/i/web/status/1242964476669898754\n",
       "1                                                                                https://conservativechoicecampaign.com/fast-and-furious-the-deep-state-playbook-revealed/\n",
       "2                                                                                                                     https://twitter.com/i/web/status/1242964474723794944\n",
       "3                                                                                                                     https://twitter.com/i/web/status/1242964475445051398\n",
       "4       https://www.politicshome.com/news/article/italian-officials-demand-health-minister-nadine-dorries-delete-fake-news-about-coronavirus-patients#.Xnvwe3DEjaI.twitter\n",
       "...                                                                                                                                                                    ...\n",
       "775410                                                                                                                https://twitter.com/i/web/status/1245138810297606149\n",
       "775411                                                                                                                https://twitter.com/i/web/status/1245138809290973187\n",
       "775412                                                                                                                https://twitter.com/i/web/status/1245138810863665152\n",
       "775413                                                                                                                https://twitter.com/i/web/status/1245138811362906112\n",
       "775414                                                                                                                https://twitter.com/i/web/status/1245138809555206144\n",
       "\n",
       "[775415 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json, os, glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "rows = []\n",
    "links = []\n",
    "#num = Path('2020-03-19.json').stat().st_size\n",
    "count=0\n",
    "\n",
    "json_dir = 'en'\n",
    "# Uses the json_dir variable to navigate to the dataset directory and 'get' all json files\n",
    "json_pattern = os.path.join(json_dir, '*.json')\n",
    "\n",
    "# Uses Glob with the json pattern variable to place all the json files and their directories in a list\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "# directory to save data to\n",
    "save_dir = \"allLinks.03.2020.EnglishTweets.ftr\"\n",
    "\n",
    "# Opens the JSON file\n",
    "for file in file_list:\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            if count > 10000:\n",
    "                break\n",
    "            count = 0\n",
    "            data = json.loads(line)\n",
    "\n",
    "            if len(data[\"entities\"][\"urls\"]) > 0:\n",
    "                count+=1\n",
    "\n",
    "            if count == 1:\n",
    "                #username\n",
    "                user_id = data[\"user\"][\"screen_name\"]\n",
    "                #location\n",
    "                user_location = data[\"user\"][\"location\"]\n",
    "                #Tweet ID\n",
    "                tweet_id = data[\"id_str\"]\n",
    "                #Hashtags\n",
    "                hashtags = data[\"entities\"][\"hashtags\"]\n",
    "                #tweet text\n",
    "                urls = data[\"entities\"][\"urls\"]\n",
    "                rows.append((urls[0].get(\"expanded_url\")))\n",
    "\n",
    "pd.options.display.max_colwidth = 500\n",
    "datas = pd.DataFrame(rows, columns=[\"urls\"])\n",
    "datas.to_feather(save_dir)\n",
    "display(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find specific element [H1]\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import feather\n",
    "from collections import Counter\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# adjustable file in ftr format\n",
    "save_dir = \"allLinks.03.2020.EnglishTweets.ftr\"\n",
    "\n",
    "# reads contents of save_dir.ftr\n",
    "read_ftr = pd.read_feather(save_dir, columns=None, use_threads=True);\n",
    "\n",
    "# finds 100 most common words\n",
    "countList = Counter(\" \".join(read_ftr[\"urls\"]).split()).most_common(100)\n",
    "f = open(\"english_Links_H1.txt\", \"w+\", encoding=\"utf8\")\n",
    "\n",
    "for i in range(len(countList)):\n",
    "    resp = requests.get(countList[i][0])\n",
    "    txt = resp.text\n",
    "    soup = BeautifulSoup(txt, 'lxml')\n",
    "    for i in range(len(soup.find_all('h1'))):\n",
    "        if i != \"JavaScript is not available.\":\n",
    "            f.write(soup.find_all('h1')[i].text)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import feather\n",
    "from collections import Counter\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# adjustable file in ftr format\n",
    "save_dir = \"allLinks.03.2020.EnglishTweets.ftr\"\n",
    "\n",
    "# reads contents of save_dir.ftr\n",
    "read_ftr = pd.read_feather(save_dir, columns=None, use_threads=True);\n",
    "\n",
    "# finds 100 most common words\n",
    "countList = Counter(\" \".join(read_ftr[\"urls\"]).split()).most_common(100)\n",
    "#print(countList)\n",
    "\n",
    "previous = \"\"\n",
    "\n",
    "for i in range(len(countList)):\n",
    "    resp = requests.get(countList[i][0])\n",
    "    txt = resp.text\n",
    "    soup = BeautifulSoup(txt, 'lxml')\n",
    "    finding = soup.body.find_all('img', alt=True)\n",
    "    searchFor = 'alt'\n",
    "    \n",
    "    with open(\"english_Links_Img_Alt.txt\", \"a\", encoding=\"utf8\") as f:\n",
    "        for j in finding:\n",
    "            if j.attrs[searchFor] == previous:\n",
    "                continue\n",
    "            elif len(j.attrs[searchFor]) > 10:\n",
    "                previous = j.attrs[searchFor]\n",
    "                f.write(j.attrs[searchFor])\n",
    "                f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import *\n",
    "import os\n",
    "\n",
    "f = open('english_Links_H1.txt', 'r', encoding='utf-8')\n",
    "raw = f.read()\n",
    "tokens = word_tokenize(raw)\n",
    "text = nltk.Text(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
