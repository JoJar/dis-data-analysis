{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feather does not support serializing <class 'pandas.core.indexes.base.Index'> for the index; you can .reset_index() to make the index into column(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5806ea0610a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_colwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mdatas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"user_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"user_location\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tweet_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"hashtags\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mdatas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_feather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_feather\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1992\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeather_format\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_feather\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1994\u001b[1;33m         \u001b[0mto_feather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1995\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1996\u001b[0m     @Appender(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\feather_format.py\u001b[0m in \u001b[0;36mto_feather\u001b[1;34m(df, path)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInt64Index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mtyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[1;34mf\"feather does not support serializing {typ} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;34m\"for the index; you can .reset_index() \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: feather does not support serializing <class 'pandas.core.indexes.base.Index'> for the index; you can .reset_index() to make the index into column(s)"
     ]
    }
   ],
   "source": [
    "import json, os, glob\n",
    "import pandas as pd\n",
    "import feather\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "rows = []\n",
    "links = []\n",
    "#num = Path('2020-03-19.json').stat().st_size\n",
    "count=0\n",
    "\n",
    "json_dir = './en'\n",
    "# Uses the json_dir variable to navigate to the dataset directory and 'get' all json files\n",
    "json_pattern = os.path.join(json_dir, '*.json')\n",
    "\n",
    "# Uses Glob with the json pattern variable to place all the json files and their directories in a list\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "# directory to save data to\n",
    "save_dir = \"allEnglishTweets.ftr\"\n",
    "\n",
    "# Opens the JSON file\n",
    "for file in file_list:\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            if count > 10000:\n",
    "                break\n",
    "            count = 0\n",
    "            data = json.loads(line)\n",
    "\n",
    "            if count == 0:\n",
    "                #username\n",
    "                user_id = data[\"user\"][\"screen_name\"]\n",
    "                #location\n",
    "                user_location = data[\"user\"][\"location\"]\n",
    "                #Tweet ID\n",
    "                tweet_id = data[\"id_str\"]\n",
    "                #Hashtags\n",
    "                hashtags = data[\"entities\"][\"hashtags\"]\n",
    "                #tweet text\n",
    "                if \"extended_tweet\" in data:\n",
    "                    text = data[\"extended_tweet\"][\"full_text\"]\n",
    "                else:\n",
    "                    text = data[\"text\"]\n",
    "                rows.append((user_id, user_location, tweet_id, hashtags, text))\n",
    "        \n",
    "pd.options.display.max_colwidth = 500\n",
    "datas = pd.DataFrame(rows, columns=[\"user_id\", \"user_location\", \"tweet_id\", \"hashtags\", \"text\"])\n",
    "datas.to_feather(save_dir)\n",
    "display(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000000/5000000 [16:43<00:00, 4980.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36585/36585 [00:00<00:00, 64176.54it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8049/8049 [00:00<00:00, 54859.80it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51214/51214 [00:00<00:00, 67070.37it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16517/16517 [00:00<00:00, 51623.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23035/23035 [00:00<00:00, 59888.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7720/7720 [00:00<00:00, 43041.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7727/7727 [00:00<00:00, 43872.42it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def concordanceToFile(conc):\n",
    "    filename = 'concordance_' + conc + '.txt'\n",
    "    conc_save = text.concordance_list(conc, lines=5000000)\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf8') as fin:\n",
    "        for i, line in enumerate(tqdm(conc_save, total=len(conc_save))):\n",
    "                fin.write(str(line).strip(\"ConcordanceLine(\") + \"\\n\")\n",
    "\n",
    "file_path = 'EN-03-2020-No-Retweets.txt'\n",
    "tokens = \"\"\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(tqdm(f.readlines(), total=5000000)):\n",
    "        tokens+=line\n",
    "        if i == 5000000:\n",
    "            tokens = nltk.word_tokenize(tokens)\n",
    "            break\n",
    "\n",
    "text = nltk.Text(tokens)\n",
    "concordanceToFile(\"I\")\n",
    "concordanceToFile(\"me\")\n",
    "concordanceToFile(\"you\")\n",
    "concordanceToFile(\"we\")\n",
    "concordanceToFile(\"they\")\n",
    "concordanceToFile(\"my\")\n",
    "concordanceToFile(\"us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>littleblondie35</td>\n",
       "      <td>Oklahoma, USA</td>\n",
       "      <td>1242964476669898754</td>\n",
       "      <td>[]</td>\n",
       "      <td>@marlenelooney You're wrong. I can tell because you're a trump hater. And you are a Democrat. That tells us all we need to know. Why don't you stop watching the fake news like CNN and MSNBC? That way you would be more informed instead of being fed with lies and twisting the truth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pathfin48237177</td>\n",
       "      <td>None</td>\n",
       "      <td>1242964473993781248</td>\n",
       "      <td>[]</td>\n",
       "      <td>@charliekirk11 The NPR one is depressing. They are a leftist propaganda network and should get ZERO funding.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Destro14352950</td>\n",
       "      <td>Youngstown, OH</td>\n",
       "      <td>1242964474723794944</td>\n",
       "      <td>[]</td>\n",
       "      <td>@achowardwriter @TappyTapin @mainerbee @NaomiAKlein Whatâ€™s the conspiracy? Like youâ€™re an expert on what politicians have done. What have your favored politicians done to make this a better country or world?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klingensmith_j</td>\n",
       "      <td>None</td>\n",
       "      <td>1242964475445051398</td>\n",
       "      <td>[]</td>\n",
       "      <td>What an Egotistical man!\\nWhat kind of conspiracy is he dreaming up?\\n@realDonaldTrump\\n\\nLives mean more than ANYONE'S ELECTION!\\nðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FSaltao</td>\n",
       "      <td>Liverpool, England</td>\n",
       "      <td>1242964475256455170</td>\n",
       "      <td>[]</td>\n",
       "      <td>Italian officials demand health minister Nadine Dorries delete 'fake news' about coronavirus patients https://t.co/Tf2VOhLoAj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078329</th>\n",
       "      <td>CBNNews</td>\n",
       "      <td>D.C.-Nashville-Jerusalem-VA</td>\n",
       "      <td>1245138809290973187</td>\n",
       "      <td>[]</td>\n",
       "      <td>Pastor Ralph Drollinger, leader and founder of Capitol Ministries, is firing back after the White House and mainstream media criticized his latest Bible study titled: \"Is God Judging America Today?\"\\nhttps://t.co/lkj1aMPqkt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078330</th>\n",
       "      <td>JudicialWatch</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1245138810863665152</td>\n",
       "      <td>[]</td>\n",
       "      <td>.@TomFitton: \"You donâ€™t have self-govt if you donâ€™t know what the government is up to. Judicial Watch has over 30 federal lawsuits on the targeting of @realDonaldTrump, the Deep State, Special Counsel Mueller, &amp;amp; other basic info requests that only Judicial Watch is fighting for.\" https://t.co/nFGndxzQkf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078331</th>\n",
       "      <td>Bet1234Michaell</td>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>1245138811362906112</td>\n",
       "      <td>[]</td>\n",
       "      <td>@Jali_Cat @SpeakerPelosi They did it on purpose. They wanted as many infected as possible. Call me a conspiracy theorist. I don't care. They wanted as many people infected as possible so that hospitals would be overrun and the death toll astronomical! https://t.co/28czDDkCV8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078332</th>\n",
       "      <td>ABSCBNNews</td>\n",
       "      <td>Manila, Philippines</td>\n",
       "      <td>1245138809555206144</td>\n",
       "      <td>[{'indices': [21, 29], 'text': 'COVID19'}]</td>\n",
       "      <td>Sa harap ng banta ng #COVID19, tamang impormasyon ang kailangan. Narito ang ilang paraan kung paano matiyak na ang nabasa mo ay \"fact\" at hindi \"disinformation.\" #LigtasPilipinas\\n\\nPara sa pinakabagong balita tungkol sa #COVID19, bumisita sa https://t.co/CMJ1iyR4Tg. https://t.co/qn1FA5veVT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078333</th>\n",
       "      <td>Ewerton34407810</td>\n",
       "      <td>None</td>\n",
       "      <td>1245138810364743693</td>\n",
       "      <td>[]</td>\n",
       "      <td>@therezafontoura @TamaraF40204218 @mancuello Fake news nada. Aconteceu AGR a noite, se informa melhor priozento</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1078334 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id                user_location             tweet_id  \\\n",
       "0        littleblondie35                Oklahoma, USA  1242964476669898754   \n",
       "1        Pathfin48237177                         None  1242964473993781248   \n",
       "2         Destro14352950               Youngstown, OH  1242964474723794944   \n",
       "3         klingensmith_j                         None  1242964475445051398   \n",
       "4                FSaltao           Liverpool, England  1242964475256455170   \n",
       "...                  ...                          ...                  ...   \n",
       "1078329          CBNNews  D.C.-Nashville-Jerusalem-VA  1245138809290973187   \n",
       "1078330    JudicialWatch               Washington, DC  1245138810863665152   \n",
       "1078331  Bet1234Michaell                 Florida, USA  1245138811362906112   \n",
       "1078332       ABSCBNNews          Manila, Philippines  1245138809555206144   \n",
       "1078333  Ewerton34407810                         None  1245138810364743693   \n",
       "\n",
       "                                           hashtags  \\\n",
       "0                                                []   \n",
       "1                                                []   \n",
       "2                                                []   \n",
       "3                                                []   \n",
       "4                                                []   \n",
       "...                                             ...   \n",
       "1078329                                          []   \n",
       "1078330                                          []   \n",
       "1078331                                          []   \n",
       "1078332  [{'indices': [21, 29], 'text': 'COVID19'}]   \n",
       "1078333                                          []   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                         text  \n",
       "0                                 @marlenelooney You're wrong. I can tell because you're a trump hater. And you are a Democrat. That tells us all we need to know. Why don't you stop watching the fake news like CNN and MSNBC? That way you would be more informed instead of being fed with lies and twisting the truth...  \n",
       "1                                                                                                                                                                                                                @charliekirk11 The NPR one is depressing. They are a leftist propaganda network and should get ZERO funding.  \n",
       "2                                                                                                             @achowardwriter @TappyTapin @mainerbee @NaomiAKlein Whatâ€™s the conspiracy? Like youâ€™re an expert on what politicians have done. What have your favored politicians done to make this a better country or world?  \n",
       "3                                                                                                                                                                                     What an Egotistical man!\\nWhat kind of conspiracy is he dreaming up?\\n@realDonaldTrump\\n\\nLives mean more than ANYONE'S ELECTION!\\nðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡  \n",
       "4                                                                                                                                                                                               Italian officials demand health minister Nadine Dorries delete 'fake news' about coronavirus patients https://t.co/Tf2VOhLoAj  \n",
       "...                                                                                                                                                                                                                                                                                                                       ...  \n",
       "1078329                                                                                       Pastor Ralph Drollinger, leader and founder of Capitol Ministries, is firing back after the White House and mainstream media criticized his latest Bible study titled: \"Is God Judging America Today?\"\\nhttps://t.co/lkj1aMPqkt  \n",
       "1078330  .@TomFitton: \"You donâ€™t have self-govt if you donâ€™t know what the government is up to. Judicial Watch has over 30 federal lawsuits on the targeting of @realDonaldTrump, the Deep State, Special Counsel Mueller, &amp; other basic info requests that only Judicial Watch is fighting for.\" https://t.co/nFGndxzQkf  \n",
       "1078331                                   @Jali_Cat @SpeakerPelosi They did it on purpose. They wanted as many infected as possible. Call me a conspiracy theorist. I don't care. They wanted as many people infected as possible so that hospitals would be overrun and the death toll astronomical! https://t.co/28czDDkCV8  \n",
       "1078332                   Sa harap ng banta ng #COVID19, tamang impormasyon ang kailangan. Narito ang ilang paraan kung paano matiyak na ang nabasa mo ay \"fact\" at hindi \"disinformation.\" #LigtasPilipinas\\n\\nPara sa pinakabagong balita tungkol sa #COVID19, bumisita sa https://t.co/CMJ1iyR4Tg. https://t.co/qn1FA5veVT  \n",
       "1078333                                                                                                                                                                                                       @therezafontoura @TamaraF40204218 @mancuello Fake news nada. Aconteceu AGR a noite, se informa melhor priozento  \n",
       "\n",
       "[1078334 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json, os, glob\n",
    "import pandas as pd\n",
    "import feather\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "rows = []\n",
    "links = []\n",
    "#num = Path('2020-03-19.json').stat().st_size\n",
    "count=0\n",
    "\n",
    "json_dir = './en'\n",
    "# Uses the json_dir variable to navigate to the dataset directory and 'get' all json files\n",
    "json_pattern = os.path.join(json_dir, '*.json')\n",
    "\n",
    "# Uses Glob with the json pattern variable to place all the json files and their directories in a list\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "# directory to save data to\n",
    "save_dir = \"EN-03-2020-No-Retweets.ftr\"\n",
    "\n",
    "# Opens the JSON file\n",
    "for file in file_list:\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            if count > 10000:\n",
    "                break\n",
    "            count = 0\n",
    "            data = json.loads(line)\n",
    "\n",
    "            if count == 0:\n",
    "                # Retweet?\n",
    "                if data[\"text\"][:2] != \"RT\":\n",
    "                    #username\n",
    "                    user_id = data[\"user\"][\"screen_name\"]\n",
    "                    #location\n",
    "                    user_location = data[\"user\"][\"location\"]\n",
    "                    #Tweet ID\n",
    "                    tweet_id = data[\"id_str\"]\n",
    "                    #Hashtags\n",
    "                    hashtags = data[\"entities\"][\"hashtags\"]\n",
    "                    # Retweet?\n",
    "                    retweet = data[\"retweeted\"]\n",
    "                    #tweet text\n",
    "                    if \"extended_tweet\" in data:\n",
    "                        text = data[\"extended_tweet\"][\"full_text\"]\n",
    "                    else:\n",
    "                        text = data[\"text\"]\n",
    "                    rows.append((user_id, user_location, tweet_id, hashtags, text))\n",
    "        \n",
    "pd.options.display.max_colwidth = 500\n",
    "datas = pd.DataFrame(rows, columns=[\"user_id\", \"user_location\", \"tweet_id\", \"hashtags\", \"text\"])\n",
    "datas.to_feather(save_dir)\n",
    "display(datas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
