{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import nltk, glob\r\n",
    "from tqdm import tqdm\r\n",
    "import os\r\n",
    "import re\r\n",
    "from num2words import num2words\r\n",
    "import import_ipynb\r\n",
    "import prepro"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from prepro.ipynb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "conc_dict = {}\r\n",
    "pronouns = [\"oн\", \"вас\",  \"вы\", \"их\",\"мен\", \"мне\", \"мы\",\"нас\", \"теб\",\"ты\", \"я\"]\r\n",
    "\r\n",
    "file_path = '../txts/Pronoun'\r\n",
    "\r\n",
    "lt = [x[0] for x in os.walk(file_path)]\r\n",
    "print(lt[1:])\r\n",
    "for n, txt_dir in enumerate(lt[1:]):\r\n",
    "    # Gets pronoun from file name\r\n",
    "    pronoun = txt_dir[21:]\r\n",
    "\r\n",
    "    # Uses the json_dir variable to navigate to the dataset directory and 'get' all json files\r\n",
    "    ftr_pattern = os.path.join(txt_dir, '*.txt')\r\n",
    "\r\n",
    "    file_list = glob.glob(ftr_pattern)\r\n",
    "    tokens = \"\"\r\n",
    "    for txt_file in file_list:\r\n",
    "        with open(txt_file, 'r', encoding='utf-8') as f:\r\n",
    "            for i, line in enumerate(tqdm(f.readlines(), total=35000)):\r\n",
    "                #remove duplicates\r\n",
    "                no_duplicates = list( dict.fromkeys(line.split()) )\r\n",
    "                tokens+=line\r\n",
    "\r\n",
    "    tokens = nltk.word_tokenize(tokens)\r\n",
    "    text = nltk.Text(tokens)\r\n",
    "    conc_dict[pronouns[n]] = text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def concord_dictionary():\r\n",
    "    pronouns = [\"он\", \"вас\",  \"вы\", \"их\",\"мен\", \"мне\", \"мы\",\"нас\", \"теб\",\"ты\", \"я\"]\r\n",
    "\r\n",
    "    for n, i in enumerate(conc_dict):\r\n",
    "        print(pronouns[n])\r\n",
    "        print(\"\\n\")\r\n",
    "        conc_save = conc_dict.get(i).concordance(pronouns[n], lines=25)\r\n",
    "        \r\n",
    "concord_dictionary()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'conc_dict' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12124/1352599022.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mconc_save\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconc_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcordance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpronouns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mconcord_dictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12124/1352599022.py\u001b[0m in \u001b[0;36mconcord_dictionary\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mpronouns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"он\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"вас\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;34m\"вы\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"их\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"мен\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"мне\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"мы\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"нас\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"теб\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"ты\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"я\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconc_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpronouns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'conc_dict' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def concordanceToFile(p_dict):\r\n",
    "    pronouns = [\"он\", \"вас\",  \"вы\", \"их\",\"мен\", \"мне\", \"мы\",\"нас\", \"теб\",\"ты\", \"я\"]\r\n",
    "\r\n",
    "    for n, i in enumerate(p_dict):\r\n",
    "        text = p_dict.get(i)\r\n",
    "        filename = '../txts/Pronoun/concordance_' + pronouns[n] + '.txt'\r\n",
    "        conc_save = text.concordance_list(pronouns[n], lines=1999000)\r\n",
    "        for conc in conc_save:\r\n",
    "            c_line = conc.line\r\n",
    "        \r\n",
    "            with open(filename, 'a', encoding='utf8') as fin:\r\n",
    "                fin.write(c_line + \"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def concordanceToFile_verbs(p_dict):\r\n",
    "    verbs = [\"отрицател\",\r\n",
    "                \"врут\",\r\n",
    "                \"пишут\",\r\n",
    "                \"врет\",\r\n",
    "                \"удивл\",\r\n",
    "                \"долбоеб\"]\r\n",
    "    \r\n",
    "    for n, i in enumerate(p_dict):\r\n",
    "        for v in verbs:\r\n",
    "            text = p_dict.get(i)\r\n",
    "            filename = '../txts/Concordance/Verbs/concordance_' + v + '.txt'\r\n",
    "            conc_save = text.concordance_list(v, lines=1999000)\r\n",
    "\r\n",
    "            for conc in conc_save:\r\n",
    "                c_line = conc.line\r\n",
    "\r\n",
    "            if len(conc_save) > 0:\r\n",
    "                with open(filename, 'a', encoding='utf8') as fin:\r\n",
    "                    fin.write(c_line + \"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "concordanceToFile_verbs(conc_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "concordanceToFile(conc_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(conc_dict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'oн': <Text: семнадцатьбраинcеллс предыдущ кром он прост выросл никак изменен...>, 'вас': <Text: coldabbess харизм эт людьм палев темн сторон дает...>, 'вы': <Text: shiningstri задач непрост силов метод неверн бездн ху...>, 'их': <Text: coldabbess харизм эт людьм палев темн сторон дает...>, 'мен': <Text: присн я доминирова одн мужчин прич сексуальн план...>, 'мне': <Text: коммунизм утоп афер единствен возможн честн заработа желан...>, 'мы': <Text: enamouredd ты немн пута общ мы собачк мы...>, 'нас': <Text: coldabbess харизм эт людьм палев темн сторон дает...>, 'теб': <Text: семнадцатьбраинcеллс предыдущ кром он прост выросл никак изменен...>, 'ты': <Text: madhousesleeps имен перв твит я испуш петиц буд...>, 'я': <Text: присн я доминирова одн мужчин прич сексуальн план...>}\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "6c91f7360f31a60595970ce0519c225953292631b532536816811087a825ec9b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}